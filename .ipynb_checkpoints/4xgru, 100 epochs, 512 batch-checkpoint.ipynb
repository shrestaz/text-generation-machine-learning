{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80xmUzUJgGWZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "efHQ8RUcwqAi",
    "outputId": "edc06fc1-b4f9-443b-c9ee-15ea40ced3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.gutenberg.org/cache/epub/345/pg345.txt\n",
      "884736/883160 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Creating and converting dataset to tensorflow\n",
    "path = tf.keras.utils.get_file('dracula.txt', 'http://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
    "text = open(path, 'rb').read().decode(encoding='utf-8')\n",
    "vocabulary = sorted(set(text))\n",
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cbCv2ccgwknz",
    "outputId": "eba84ade-0ebc-497d-c378-c0206b65837e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  883114\n",
      "Total Vocabulary:  102\n"
     ]
    }
   ],
   "source": [
    "# map unique characters to indices and vice versa\n",
    "charMapping = {u:i for i, u in enumerate(vocabulary)}\n",
    "indiceMapping = np.array(vocabulary)\n",
    "text_as_int = np.array([charMapping[c] for c in text])\n",
    "\n",
    "sequence_length = 100\n",
    "examples_per_epoch = len(text)//sequence_length # floor division\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)\n",
    "\n",
    "num_of_characters = len(text)\n",
    "num_of_vocabulary = len(vocabulary)\n",
    "print(\"Total Characters: \", num_of_characters)\n",
    "print(\"Total Vocabulary: \", num_of_vocabulary)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gpz5u3W32hK"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE # floor division\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "sj5x42V22Y3U",
    "outputId": "a3413762-0925-41f8-d1c7-fe80903fd96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "embedding_dimension = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "lstm = tf.keras.layers.CuDNNLSTM # fast LSTM implementation backed by cuDNN\n",
    "gru = tf.keras.layers.CuDNNGRU # fast LSTM implementation backed by cuDNN\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, units, batch_size, drop_out):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]), # Input layer\n",
    "    gru(rnn_units, # Hidden layer 1\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='lecun_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dropout(drop_out),\n",
    "    gru(rnn_units, # Hidden layer 2\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='lecun_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dropout(drop_out),\n",
    "    gru(rnn_units, # Hidden layer 3\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='lecun_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dropout(drop_out),\n",
    "    gru(rnn_units, # Hidden layer 4\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='lecun_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dropout(drop_out),\n",
    "    tf.keras.layers.Dense(vocab_size) # Output layer\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(\n",
    "  vocab_size = vocabulary_size, \n",
    "  embedding_dim=embedding_dimension, \n",
    "  units=rnn_units, \n",
    "  batch_size=BATCH_SIZE,\n",
    "  drop_out=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1A0cMnYh_RK"
   },
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  \n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3645
    },
    "colab_type": "code",
    "id": "hsQZCK_-42_R",
    "outputId": "2caaf970-7898-48c8-cd5f-1aec5e269ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (512, 100, 102)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.62572\n",
      "Epoch 1/100\n",
      "16/17 [===========================>..] - ETA: 2s - loss: 4.1308WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "17/17 [==============================] - 36s 2s/step - loss: 4.0789\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 3.1619\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 3.0251\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 2.7986\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 2.5419\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 2.3399\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 2.2277\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 2.1352\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 2.0480\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.9613\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.8780\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.8031\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.7395\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.6834\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.6343\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.5917\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.5562\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.5226\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.4936\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.4676\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 37s 2s/step - loss: 1.4446\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 37s 2s/step - loss: 1.4233\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.4024\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.3839\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.3665\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.3525\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.3365\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.3211\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.3067\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2941\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2811\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2671\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2554\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2438\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2315\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2206\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.2098\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1976\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1858\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1735\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1638\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1534\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1404\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1305\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1197\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.1069\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0983\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0860\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0738\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0643\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0516\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0403\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0285\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0175\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 1.0060\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9935\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9823\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9713\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9586\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9504\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9377\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9256\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.9132\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 39s 2s/step - loss: 0.8999\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8871\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8814\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8688\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8563\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8440\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8333\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8237\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8127\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.8039\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 37s 2s/step - loss: 0.7954\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7857\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7711\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7609\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7512\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7442\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7326\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7211\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7146\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.7084\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6993\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6913\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6822\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6791\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6712\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6624\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6522\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6458\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6407\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6306\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6258\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6201\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6136\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.6071\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.5997\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.5944\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 38s 2s/step - loss: 0.5893\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n",
    "\n",
    "model.compile(tf.train.AdamOptimizer(), loss=loss)\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "EPOCHS=100\n",
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrPopEcKfTbv"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = build_model(vocabulary_size, embedding_dimension, rnn_units, batch_size=1, drop_out=0.2)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_Evgr4Pwydc"
   },
   "outputs": [],
   "source": [
    "# Generate text algorithm\n",
    "def generate_text(model, num_char_to_generate, temperature, start_string):\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "  input_eval = [charMapping[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_char_to_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      text_generated.append(indiceMapping[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1319
    },
    "colab_type": "code",
    "id": "n-jikOVZ710c",
    "outputId": "a71e6174-ce59-46df-aca2-7e4f87c19795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b38a7cfe830f>:18: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "Dracula moved to Copenhagen because you have all the papers from the safety-pin. I shall not even feel the confident that I have not\n",
      "had much time for friendships; but since they would be\n",
      "also that nothing husband to say that she was still with the wind blow was a projection of morning, and with the effort his\n",
      "eyes seemed stream of the sun was help, dear Lucy's sake, for not the soul as much\n",
      "as a stranger, and what have I done? What have I done to do in the morning? I am afraid to think of\n",
      "     hand.\"\n",
      "\n",
      "He answered quietly at his time a moment's\n",
      "pause to laid his head but a warning fancy of the tide. Then there\n",
      "are move and his brain fever so soon as I should have the matter over for a while.\n",
      "\n",
      "       *       *       *       *       *\n",
      "\n",
      "_29 July_.--There seems some doom over the same, and where and his wife went back to the room, and looked at the last, I feel my heart since She has turned the\n",
      "correspondent in a few minutes just before the stranger had greatly improveding despite these women, even if he did not stop him. His eyes glassed the\n",
      "wolves and the rest. I saw the involuntary shorthand find our man, though it were of\n",
      "the night. I am brought for the Count, for there is not a moment to lose it?\" He stopped and\n",
      "looked down on a pause, and then he said to me:--\n",
      "\n",
      "\"And now the same time must be no chance.\" He answered in growing passion of his\n",
      "arms around her head his hands ready. Some of them, as I stood here. It may be that she could not be so will\n",
      "it, now. But the instant we saw with a special reason for sunrise and sunset, that\n",
      "we can say wherefore had not tell him that he must go she was that no one who\n",
      "were--which we can go to sleep without fear. I shall not fear to sleep in any place\n",
      "where treasure has been concealed. \"That treasure has been so much pain and the feelings of the night does not\n",
      "seem to have shrunkers, and that when you shall be sorrow from yourself and\n",
      "stupid with paragraph 1.E.8 or other free. I shall take him and distribution of this\n",
      "even one little woman who served us shall laid beside she was as if he had seen him often being\n",
      "so well as I could, but I could see even Arthur's friend and Dr.\n",
      "Seward's Diary._\n",
      "\n",
      "_20 September._--I am puzzled afresh the shove of many feet which I have had a great strength of my\n",
      "life. The old fellow's servant--the souls of thousands of\n",
      "life in a box me.\"\n",
      "\n",
      "\"Now, sir,\" he said, \"clas had a shadow over her, and she drew back with a sort of\n",
      "patch of grey light as if ready, and when he was beginning to hope that the snow\n",
      "manns help to see his face, but he said nothing.\n",
      "\n",
      "At last there came a broken voice and a blood in her sleep. Wake that poor boyy,\n",
      "that so gave mack off his head and brave that we could have\n",
      "happened puzzled the attendant: \"Do not forget how time flies\n",
      "through the strength of negrock was so rude around. I did not\n",
      "take suffered, but looked at me with so much harm and holding up his\n",
      "hand on the tomb. He unlocked the door, and seeing a narrow one of his\n",
      "breath, and he came to Lucy and I shall watch up in a train from the tame matters. 'ay, looking at my window,\n",
      "and was holding towards him the envelope which contained the Salley\n",
      "foreigners, that he has so many opportunities of starting that I had noticed in\n",
      "the night. I am glad to say that, though I was going to bed, and found you so place at the thought got a new fashions.\n",
      "\n",
      "Before long the strange relapse from one time, when her body must\n",
      "have been crying times more difficult in that part of the work; and in\n",
      "a story means of life in my account of the Count's\n",
      "lamp, but she did not seem to mind, he said to me:--\n",
      "\n",
      "\"And now, Art, you have won flies any further creek. We all instinctively drawn\n",
      "back. We shall be on the sofa, and raised both her hands and south of the port. We must push\n",
      "on his expected containing a criminal's breast and tore it in two. Van Helsing said\n",
      "good-bye, and holding up the castle for the door souls at the time has come, and when we meet him the others at first in the\n",
      "morning; I cannot mean to stand them, and we felt that our best and dearest friend was gone from us. Then Mrs. Westenra\n",
      "think that they are knitting together in life a word at once. I was so hard to read all the terms of this agreement\n",
      "and help promised to post the war which was not lost something of the\n",
      "girls, and the third that I had seen used as ever. But there was no need to speak to him for\n",
      "in the night, and found that Godalming and Mr. Morris are\n",
      "coming to meet us. Mina is sleeping now, calmly and rolled up in a ruby\n",
      "gang--the grim surroundings, of that terrible\n",
      "experience in Transylvania; and Transylvania is not England. Our ways are\n",
      "not your ways, and there shall be no chance.\" He said that in all his statement is coming\n",
      "confidence in masqueral with the window. Then I began to read, and let me be ready for your journey. I never know nothing of all this rest, laying his hand on my\n",
      "heart to prepare for the whirl and restore her, for now she is all sweet and bright and\n",
      "strained\n"
     ]
    }
   ],
   "source": [
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "\n",
    "print(generate_text(model, 5000, .6, \"Dracula moved to Copenhagen because \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "9q6NKUhHMERD",
    "outputId": "424704c5-4081-4122-e592-c63c7624039a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAJQCAYAAAAg+ngHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "loss = history.history['loss']\n",
    "newLoss = np.squeeze(loss)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(newLoss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text Generation with RNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
